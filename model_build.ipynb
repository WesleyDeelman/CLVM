{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375a7fc0",
   "metadata": {},
   "source": [
    "### Our main objective for this code is to find segments that vary in payment amounts/behaviour the assumption being that each has a stable segment level performance, which is a reasonable assumption because we have cohorts that are the same with respect to the segment/model score.\n",
    "\n",
    "We are working with synthetic data, so there are distributions and such that doesn't follow the norm for real data, despite this - building the scaffolding for creating a CLV will still be pertinent.\n",
    "\n",
    "Below is a class that loads the synthetic data, and maps the columns CustomerID,TransactionDate,TransactionAmount to the correct name. There are also methods in this class for creating RFM measures, RFM Segments, Demographics and Transaction Descriptor features (which I dont use), if you can do something useful with it then by all means.\n",
    "\n",
    "Please Note that the dataloader, and rfm methods are general methods they can be used with any data that contains the columns CustomerID,TransactionID,TransactionDate,TransactionAmount.\n",
    "\n",
    "I will close off by saying that the point of this exercise is to end off with segments that have stable performance at the \"crowd\" level. Thus nullifying the problem of high variance when trying to do a regression.\n",
    "\n",
    "Once we have these segments, we have a choice of 2, we will then extrapolate payments per cohort/crowd/group. That will be the next step, this work will be carried out in a seperate notebook and class with written for the Vintage object with optimisation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1e85ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import rfmbinner\n",
    "import sklearn\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import optuna\n",
    "import random\n",
    "\n",
    "class DataLoader:\n",
    "    \n",
    "    def __init__(self,path,customer_id,transaction_id,transaction_date,amount):\n",
    "        \"\"\"\n",
    "        Initialize the DataLoader.\n",
    "\n",
    "        Parameters:\n",
    "            path (str): Path to the CSV file.\n",
    "            customer_id (str): Column name for customer IDs.\n",
    "            transaction_id (str): Column name for transaction IDs.\n",
    "            transaction_date (str): Column name for transaction dates.\n",
    "            amount (str): Column name for transaction amounts.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.customer_id = customer_id\n",
    "        self.transaction_id = transaction_id\n",
    "        self.transaction_date = transaction_date \n",
    "        self.amount = amount \n",
    "        \n",
    "    def fetch_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch raw CSV data from the specified path.\n",
    "\n",
    "        Parameters:\n",
    "            path (str): Path to the CSV file.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Loaded data.\n",
    "        \"\"\"\n",
    "        data_path = Path(self.path)\n",
    "        if not data_path.exists():\n",
    "            raise FileNotFoundError(f\"CSV file not found at: {data_path}\")\n",
    "        data = pd.read_csv(data_path)\n",
    "        data.rename(columns={self.customer_id:'CustomerID',\n",
    "                             self.transaction_id: 'TransactionID',\n",
    "                             self.transaction_date: 'Date',\n",
    "                             self.amount: 'Amount'}, inplace=True)\n",
    "        data['Date'] = pd.to_datetime(data['Date'],format='%Y-%m-%d')\n",
    "        return data\n",
    "    \n",
    "    def calculate_rfm(self, snapshot_date: str, window: pd.Timedelta,df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate RFM metrics for customer segmentation.\n",
    "\n",
    "        Parameters:\n",
    "            snapshot_date (str): Date to calculate recency from (YYYY-MM-DD).\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: RFM metrics per CustomerID.\n",
    "        \"\"\"\n",
    "        data = df.copy()\n",
    "        snapshot = pd.to_datetime(snapshot_date)\n",
    "        data['Date'] = pd.to_datetime(data.Date)\n",
    "        data  = data[(data.Date<snapshot) & (data.Date>(snapshot-window))]\n",
    "        data['recency'] = (snapshot - pd.to_datetime(data['Date'])).dt.days\n",
    "        rfm = data.groupby('CustomerID').agg({\n",
    "            'recency': 'min',\n",
    "            'TransactionID': 'count',               # frequency: number of transactions\n",
    "            'Amount': 'sum'             # monetary: total spend\n",
    "        }).reset_index()\n",
    "\n",
    "        rfm.rename(columns={'TransactionID': 'frequency', 'Amount': 'monetary'}, inplace=True)\n",
    "        rfm['date'] = snapshot_date\n",
    "\n",
    "        return rfm[['CustomerID', 'date', 'recency', 'frequency', 'monetary']]\n",
    "    \n",
    "    def calculate_target(self,date: str, window_size: pd.Timedelta, \\\n",
    "                         repurchase_threshold: float, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculating the target for the model\n",
    "        Parameters:\n",
    "            date (str): Date to calculate recency from (YYYY-MM-DD).\n",
    "            window_size (pd.Timedelta): Number of days in which to consider repurchase\n",
    "            repurchase_threshold: Minimum spend to be considered a repurchase\n",
    "        Returns:\n",
    "            pd.DataFrame: Target per CustomerID.\n",
    "        \"\"\"\n",
    "        #caculate whether a customer made total purchases after date exceeding repurchase threshold\n",
    "        data = df.copy()\n",
    "        future_purchases = data[(data['Date'] > date) & \\\n",
    "                                (data['Date'] <= date + window_size)]\n",
    "\n",
    "        target_customers = future_purchases.groupby('CustomerID')[['Amount']].sum()\n",
    "        target_customers = target_customers[target_customers >= repurchase_threshold].index\n",
    "\n",
    "        total_future_purchases = future_purchases.groupby('CustomerID')[['Amount']].sum()\n",
    "        data = data.merge(total_future_purchases.rename(columns={'Amount': 'subsequent_purchases'}),\n",
    "                            on='CustomerID', how='left')\n",
    "        data['subsequent_purchases'] = data['subsequent_purchases'].fillna(0)\n",
    "\n",
    "        data['target'] = data['CustomerID'].isin(target_customers).astype(int)\n",
    "        data['date'] = date\n",
    "        return data[['CustomerID','date','target','subsequent_purchases']].drop_duplicates()\n",
    "    \n",
    "    def rfm_segments(self,date: str, window: pd.Timedelta, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Segments customers based on their RFM score.\n",
    "\n",
    "        Parameters:\n",
    "            date (str): Date to calculate recency from (YYYY-MM-DD).\n",
    "            df (pd.DataFrame): Raw transactional data.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: RFM segments per CustomerID.\n",
    "        \"\"\"\n",
    "        data = df.copy()\n",
    "        data = self.calculate_rfm(date,window,data)\n",
    "        # Create RFM scores\n",
    "        data['r_score'] = pd.qcut(data['recency'].rank(method='first'), 5, labels=[5, 4, 3, 2, 1])\n",
    "        data['f_score'] = pd.qcut(data['frequency'].rank(method='first'), 5, labels=[1, 2, 3, 4, 5])\n",
    "        data['m_score'] = pd.qcut(data['monetary'].rank(method='first'), 5, labels=[1, 2, 3, 4, 5])\n",
    "        data['rfm_score'] = data['r_score'].astype(str) + \\\n",
    "                            data['f_score'].astype(str) + \\\n",
    "                            data['m_score'].astype(str)\n",
    "        data['rfm_score_int'] = data['r_score'].astype(int) + \\\n",
    "                                data['f_score'].astype(int)+ \\\n",
    "                                data['m_score'].astype(int)           \n",
    "        #create a dicitionary with the rfm_score that maps into segment, the key must be a regex\n",
    "        segment_map = {\n",
    "                        r'^55[1-5]$': 'Champions',\n",
    "                        r'^54[1-5]$': 'Loyal Customers',\n",
    "                        r'^45[1-5]$': 'Potential Loyalists',\n",
    "                        r'^53[1-5]$': 'New or Returning Customers',\n",
    "                        r'^33[1-5]$': 'Promising',\n",
    "                        r'^22[1-5]$': 'Needs Attention',\n",
    "                        r'^\\d{3}$': 'Others'  # Matches any other 3-digit score\n",
    "                    }\n",
    "        data['segment'] = data['rfm_score'].replace(segment_map, regex=True)\n",
    "        data['date'] = date\n",
    "        return data[['CustomerID', 'date', 'rfm_score','rfm_score_int', 'segment']]\n",
    "    \n",
    "    def dedup_demographic_variables(self,df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Deduplicate demographic variables for each customer, keeping the latest entry.\n",
    "        \n",
    "        Parameters:\n",
    "            df (pd.DataFrame): Raw transactional data with demographic information.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Deduplicated demographic data per CustomerID.\n",
    "        \"\"\"\n",
    "        data = df.copy()\n",
    "        data['Date'] = pd.to_datetime(data['Date'],format='%m-%d-%Y %H:%M:%S')\n",
    "        \n",
    "        # Sort by CustomerID and Date to get the most recent demographic info\n",
    "        data = data.sort_values(by=['CustomerID', 'Date'], ascending=True)\n",
    "        \n",
    "        # Drop duplicates, keeping the last (most recent) entry for each CustomerID\n",
    "        # Assuming demographic variables are 'Gender', 'Age', 'Age Group', extend to the actual list\n",
    "        demographic_cols = ['CustomerID', 'Gender', 'Age','Province']\n",
    "        deduplicated_demographics = data[demographic_cols].drop_duplicates(subset=['CustomerID'], keep='last')\n",
    "        \n",
    "        return deduplicated_demographics\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8744700a",
   "metadata": {},
   "source": [
    "For the code below the process is as follows:\n",
    "\n",
    "1. Initialise a dataloader\n",
    "2. Fetch the synthetic data\n",
    "3. Run the appropriate methods of the dataloader in order to create a collection of features\n",
    "4. We join all the features together and create a \"model_data\" dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1fa2e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'path':r'data\\customer_transaction_data.csv',\n",
    "            'customer_id':'CustomerID',\n",
    "            'transaction_id':'TransactionID',\n",
    "            'transaction_date':'PurchaseDate',\n",
    "            'amount':'TotalAmount'}\n",
    "loader = DataLoader(**params)\n",
    "data = loader.fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f6963acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2022-08-30'\n",
    "end_date = pd.to_datetime('2025-09-26')\n",
    "pivot_date = pd.to_datetime(start_date)\n",
    "rfms = []\n",
    "targets = []\n",
    "rfm_segments = []\n",
    "transaction_descriptor_data = []\n",
    "\n",
    "while pivot_date<end_date:\n",
    "    rfms.append(loader.calculate_rfm(pivot_date,pd.Timedelta(days=99999),data))\n",
    "    rfm_segments.append(loader.rfm_segments(pivot_date,pd.Timedelta(days=99999),data))\n",
    "    targets.append(loader.calculate_target(pivot_date,pd.Timedelta(weeks=56),0,data))\n",
    "    pivot_date+=pd.Timedelta(weeks=2)\n",
    "\n",
    "rfm_data = pd.concat(rfms)\n",
    "target_data = pd.concat(targets)\n",
    "rfm_segments = pd.concat(rfm_segments)\n",
    "dem_data = loader.dedup_demographic_variables(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b6986d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bfad895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = rfm_data.merge(target_data,how='left',left_on=['CustomerID','date'],right_on=['CustomerID','date'])\n",
    "model_data = model_data.merge(dem_data,how='left',left_on='CustomerID',right_on='CustomerID')\n",
    "#model_data = model_data.merge(transaction_descriptor_data,how='left', left_on=['CustomerID','date'],right_on=['CustomerID','date'])\n",
    "model_data = model_data.merge(rfm_segments.drop('segment',axis=1),how='left', left_on=['CustomerID','date'],right_on=['CustomerID','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "84a77c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['recency', 'frequency', 'monetary', 'target', 'subsequent_purchases',\n",
       "       'Gender', 'Age', 'Province', 'rfm_score_int'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_date_of_training = '2024-07-31'\n",
    "model_data = model_data.set_index(['CustomerID','date']).drop('rfm_score',axis=1)\n",
    "model_data = model_data[model_data.index.get_level_values(1)<end_date_of_training]\n",
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "95e9e929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "221f1629-34cc-4562-9417-293cb8cd7df0",
       "rows": [
        [
         "0",
         "0.8824706371479056"
        ],
        [
         "1",
         "0.11752936285209438"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "target\n",
       "0    0.882471\n",
       "1    0.117529\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.target.value_counts()/len(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4167c416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 09:36:20,158] A new study created in memory with name: no-name-1db2ca28-83ea-4a8f-88e8-140edf7f1212\n",
      "[I 2025-08-12 09:36:21,821] Trial 0 finished with value: 0.7095548875210336 and parameters: {'booster': 'dart', 'lambda': 8.135327860297275e-06, 'alpha': 0.00683797035719235, 'subsample': 0.5523321058829399, 'colsample_bytree': 0.8133459598113937, 'max_depth': 9, 'eta': 0.19452396856205204, 'scale_pos_weight': 0.17518032947139905}. Best is trial 0 with value: 0.7095548875210336.\n",
      "[I 2025-08-12 09:36:23,150] Trial 1 finished with value: 0.6646575269817967 and parameters: {'booster': 'dart', 'lambda': 1.7164525442382703, 'alpha': 0.004231929542459651, 'subsample': 0.8660694366651029, 'colsample_bytree': 0.6650497001231326, 'max_depth': 7, 'eta': 0.07023903743419774, 'scale_pos_weight': 0.12630619554311395}. Best is trial 0 with value: 0.7095548875210336.\n",
      "[I 2025-08-12 09:36:23,982] Trial 2 finished with value: 0.6891251612178801 and parameters: {'booster': 'gbtree', 'lambda': 2.135689224604708e-08, 'alpha': 3.2301944475682575e-08, 'subsample': 0.8959657873495455, 'colsample_bytree': 0.8126882195675806, 'max_depth': 6, 'eta': 0.2227316205278654, 'scale_pos_weight': 0.5367812782707915}. Best is trial 0 with value: 0.7095548875210336.\n",
      "[I 2025-08-12 09:36:25,525] Trial 3 finished with value: 0.6949776108940995 and parameters: {'booster': 'dart', 'lambda': 0.07579984736334235, 'alpha': 0.14477091405448575, 'subsample': 0.9757297552369113, 'colsample_bytree': 0.5198672537552691, 'max_depth': 8, 'eta': 0.29496387488556375, 'scale_pos_weight': 0.35475384435665114}. Best is trial 0 with value: 0.7095548875210336.\n",
      "[I 2025-08-12 09:36:26,420] Trial 4 finished with value: 0.6975786228890435 and parameters: {'booster': 'gbtree', 'lambda': 0.002910986888489641, 'alpha': 8.409906446815325e-07, 'subsample': 0.939589869046068, 'colsample_bytree': 0.7701375771206285, 'max_depth': 9, 'eta': 0.11807848310808736, 'scale_pos_weight': 0.07930751950405479}. Best is trial 0 with value: 0.7095548875210336.\n",
      "[I 2025-08-12 09:36:28,052] Trial 5 finished with value: 0.7265491699514403 and parameters: {'booster': 'gbtree', 'lambda': 0.03696746882315624, 'alpha': 0.000728196733809398, 'subsample': 0.7658898677130801, 'colsample_bytree': 0.972847759758294, 'max_depth': 6, 'eta': 0.21513758412220776, 'scale_pos_weight': 0.9850241330492921}. Best is trial 5 with value: 0.7265491699514403.\n",
      "[I 2025-08-12 09:36:28,818] Trial 6 finished with value: 0.683079282861243 and parameters: {'booster': 'gbtree', 'lambda': 3.96098699095767e-06, 'alpha': 0.003785541325245474, 'subsample': 0.5492633557184908, 'colsample_bytree': 0.9562383641166257, 'max_depth': 6, 'eta': 0.23724593107182104, 'scale_pos_weight': 0.33568924545969636}. Best is trial 5 with value: 0.7265491699514403.\n",
      "[I 2025-08-12 09:36:29,855] Trial 7 finished with value: 0.6800471519591467 and parameters: {'booster': 'gbtree', 'lambda': 2.385856809771504, 'alpha': 0.41409982313807403, 'subsample': 0.6186961604594601, 'colsample_bytree': 0.9097754446893676, 'max_depth': 5, 'eta': 0.12837790888449244, 'scale_pos_weight': 0.707577260527828}. Best is trial 5 with value: 0.7265491699514403.\n",
      "[I 2025-08-12 09:36:31,832] Trial 8 finished with value: 0.6548440068943226 and parameters: {'booster': 'gblinear', 'lambda': 0.014972972579209742, 'alpha': 0.001364839516969676, 'subsample': 0.7624362841158624, 'colsample_bytree': 0.5149015380600127, 'max_depth': 5, 'eta': 0.28679450462839334, 'scale_pos_weight': 0.8213752353259568}. Best is trial 5 with value: 0.7265491699514403.\n",
      "[I 2025-08-12 09:36:33,287] Trial 9 finished with value: 0.6720951610479572 and parameters: {'booster': 'dart', 'lambda': 2.243921452545553e-08, 'alpha': 1.5476952669516714e-07, 'subsample': 0.7433055308204698, 'colsample_bytree': 0.548779662590688, 'max_depth': 7, 'eta': 0.11850819610632782, 'scale_pos_weight': 0.18156511518006624}. Best is trial 5 with value: 0.7265491699514403.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94    428015\n",
      "           1       0.78      0.07      0.13     56884\n",
      "\n",
      "    accuracy                           0.89    484899\n",
      "   macro avg       0.84      0.53      0.53    484899\n",
      "weighted avg       0.88      0.89      0.85    484899\n",
      "\n",
      "ROC AUC: 0.6779150278540018\n"
     ]
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    model_data.drop(['target', 'subsequent_purchases'], axis=1),\n",
    "    model_data['target'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "for col in X_train.columns:\n",
    "    sample = X_train[col].iloc[0]\n",
    "    if isinstance(sample, (list, np.ndarray)):\n",
    "        print(f\"Column '{col}' contains unhashable types: {type(sample)}\")\n",
    "\n",
    "encoder = ce.TargetEncoder()\n",
    "X_train = encoder.fit_transform(X_train, y_train)\n",
    "X_test = encoder.transform(X_test)\n",
    "joblib.dump(encoder,r'data\\encoder.pkl')\n",
    "\n",
    "# Optuna + XGBoost training\n",
    "def train_xgboost_with_optuna(X, y, n_trials=10, test_size=0.2, random_state=42):\n",
    "    X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"verbosity\": 0,\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\",\"gblinear\"]),\n",
    "            \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 10.0, log=True),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 10.0, log=True),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"eta\": trial.suggest_float(\"eta\", 0.01, 0.3),\n",
    "            \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\",0,1)\n",
    "        }\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        model = xgb.train(params, dtrain, num_boost_round=50,\n",
    "                          evals=[(dval, \"validation\")],\n",
    "                          early_stopping_rounds=10,\n",
    "                          verbose_eval=False)\n",
    "        preds = model.predict(dval)\n",
    "        return sklearn.metrics.roc_auc_score(y_val, preds)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_params.update({\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\"\n",
    "    })\n",
    "\n",
    "    final_model = xgb.train(best_params, xgb.DMatrix(X, label=y), num_boost_round=study.best_trial.number)\n",
    "    return final_model, study\n",
    "\n",
    "# Train and evaluate\n",
    "model, study = train_xgboost_with_optuna(X_train, y_train)\n",
    "y_probs = model.predict(xgb.DMatrix(X_test))\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_test, y_probs > 0.5))\n",
    "print(\"ROC AUC:\", sklearn.metrics.roc_auc_score(y_test, y_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cea97a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6779150278540018"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(y_test,model.predict(xgb.DMatrix(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2fbe8fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\score_bins.pkl']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['QSegment'],score_bins= pd.cut(y_probs,bins=[-np.inf,0.11,0.12,np.inf],retbins=True)\n",
    "joblib.dump(score_bins,r'data\\score_bins.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a13d6154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesle\\AppData\\Local\\Temp\\ipykernel_22308\\238198811.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary = summary_data.groupby('QSegment').agg({'recency':'count','monetary':'sum','target':'sum','subsequent_purchases':'sum'})\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "QSegment",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Purchase Rate",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prior_purchases in ZAR",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Value %",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AVG subs. spend in ZAR",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subsequent_purchases in ZAR (3 month window)",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "b529b6cd-3db4-4507-9eef-7bc91d6a4423",
       "rows": [
        [
         "(-inf, 0.11]",
         "214560",
         "7.39%",
         "R 28,261,630.67",
         "32.20%",
         "R 11.34",
         "R 2,433,753.02"
        ],
        [
         "(0.11, 0.12]",
         "154768",
         "8.37%",
         "R 16,243,021.99",
         "18.50%",
         "R 13.35",
         "R 2,065,832.25"
        ],
        [
         "(0.12, inf]",
         "115571",
         "24.30%",
         "R 43,272,547.25",
         "49.30%",
         "R 65.22",
         "R 7,537,602.14"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Purchase Rate</th>\n",
       "      <th>prior_purchases in ZAR</th>\n",
       "      <th>Value %</th>\n",
       "      <th>AVG subs. spend in ZAR</th>\n",
       "      <th>subsequent_purchases in ZAR (3 month window)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QSegment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-inf, 0.11]</th>\n",
       "      <td>214560</td>\n",
       "      <td>7.39%</td>\n",
       "      <td>R 28,261,630.67</td>\n",
       "      <td>32.20%</td>\n",
       "      <td>R 11.34</td>\n",
       "      <td>R 2,433,753.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.11, 0.12]</th>\n",
       "      <td>154768</td>\n",
       "      <td>8.37%</td>\n",
       "      <td>R 16,243,021.99</td>\n",
       "      <td>18.50%</td>\n",
       "      <td>R 13.35</td>\n",
       "      <td>R 2,065,832.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.12, inf]</th>\n",
       "      <td>115571</td>\n",
       "      <td>24.30%</td>\n",
       "      <td>R 43,272,547.25</td>\n",
       "      <td>49.30%</td>\n",
       "      <td>R 65.22</td>\n",
       "      <td>R 7,537,602.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Count Purchase Rate prior_purchases in ZAR Value %  \\\n",
       "QSegment                                                            \n",
       "(-inf, 0.11]  214560         7.39%        R 28,261,630.67  32.20%   \n",
       "(0.11, 0.12]  154768         8.37%        R 16,243,021.99  18.50%   \n",
       "(0.12, inf]   115571        24.30%        R 43,272,547.25  49.30%   \n",
       "\n",
       "             AVG subs. spend in ZAR  \\\n",
       "QSegment                              \n",
       "(-inf, 0.11]                R 11.34   \n",
       "(0.11, 0.12]                R 13.35   \n",
       "(0.12, inf]                 R 65.22   \n",
       "\n",
       "             subsequent_purchases in ZAR (3 month window)  \n",
       "QSegment                                                   \n",
       "(-inf, 0.11]                               R 2,433,753.02  \n",
       "(0.11, 0.12]                               R 2,065,832.25  \n",
       "(0.12, inf]                                R 7,537,602.14  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_data = X_test.merge(target_data,how='left', left_on=['CustomerID','date'], right_on=['CustomerID','date'])\n",
    "summary = summary_data.groupby('QSegment').agg({'recency':'count','monetary':'sum','target':'sum','subsequent_purchases':'sum'})\n",
    "summary = summary.rename(columns = {'recency':'Count','monetary':'prior_purchases','target':'Purchase Rate'})\n",
    "summary['prior_purchases in ZAR'] = summary.prior_purchases.apply(lambda x: f'R {x:,.2f}')\n",
    "summary['Value %'] = (summary['prior_purchases']/summary['prior_purchases'].sum()*100).apply(lambda x: f'{x:.2f}%')\n",
    "summary['AVG subs. spend in ZAR'] = (summary['subsequent_purchases']/summary.Count).apply(lambda x: f'R {x:.2f}')\n",
    "summary['subsequent_purchases in ZAR (3 month window)'] = summary.subsequent_purchases.apply(lambda x: f\"R {x:,.2f}\")\n",
    "summary['Purchase Rate'] =  (summary['Purchase Rate']/summary.Count).apply( lambda x: f'{x:.2%}')\n",
    "summary.drop(['prior_purchases','subsequent_purchases'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6707f5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "rfm_score_int",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Purchase Rate",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prior_purchases in ZAR",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Value %",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AVG subs. spend in ZAR",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subsequent_purchases in ZAR (3 month window)",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "fa05e0d2-375e-4090-9c2f-cfed2e1a0237",
       "rows": [
        [
         "3",
         "5404",
         "8.14%",
         "R 109,079.32",
         "0.12%",
         "R 12.52",
         "R 67,672.48"
        ],
        [
         "4",
         "15422",
         "8.02%",
         "R 521,860.06",
         "0.59%",
         "R 13.40",
         "R 206,710.74"
        ],
        [
         "5",
         "29059",
         "8.27%",
         "R 1,465,486.20",
         "1.67%",
         "R 13.03",
         "R 378,765.21"
        ],
        [
         "6",
         "47067",
         "7.73%",
         "R 3,310,910.84",
         "3.77%",
         "R 12.24",
         "R 576,140.59"
        ],
        [
         "7",
         "61423",
         "7.50%",
         "R 5,696,871.95",
         "6.49%",
         "R 11.48",
         "R 705,198.68"
        ],
        [
         "8",
         "66861",
         "8.14%",
         "R 8,023,284.60",
         "9.14%",
         "R 12.75",
         "R 852,480.61"
        ],
        [
         "9",
         "63893",
         "8.30%",
         "R 9,225,249.60",
         "10.51%",
         "R 13.39",
         "R 855,376.33"
        ],
        [
         "10",
         "55189",
         "9.37%",
         "R 9,437,714.52",
         "10.75%",
         "R 16.15",
         "R 891,531.20"
        ],
        [
         "11",
         "43152",
         "11.54%",
         "R 8,882,400.54",
         "10.12%",
         "R 19.36",
         "R 835,498.79"
        ],
        [
         "12",
         "32407",
         "14.91%",
         "R 8,271,029.40",
         "9.42%",
         "R 30.25",
         "R 980,317.83"
        ],
        [
         "13",
         "25417",
         "20.12%",
         "R 8,536,711.40",
         "9.73%",
         "R 46.59",
         "R 1,184,071.28"
        ],
        [
         "14",
         "21192",
         "29.01%",
         "R 10,175,826.43",
         "11.59%",
         "R 82.96",
         "R 1,757,985.54"
        ],
        [
         "15",
         "18413",
         "41.11%",
         "R 14,120,775.03",
         "16.09%",
         "R 149.10",
         "R 2,745,438.15"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Purchase Rate</th>\n",
       "      <th>prior_purchases in ZAR</th>\n",
       "      <th>Value %</th>\n",
       "      <th>AVG subs. spend in ZAR</th>\n",
       "      <th>subsequent_purchases in ZAR (3 month window)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfm_score_int</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5404</td>\n",
       "      <td>8.14%</td>\n",
       "      <td>R 109,079.32</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>R 12.52</td>\n",
       "      <td>R 67,672.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15422</td>\n",
       "      <td>8.02%</td>\n",
       "      <td>R 521,860.06</td>\n",
       "      <td>0.59%</td>\n",
       "      <td>R 13.40</td>\n",
       "      <td>R 206,710.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29059</td>\n",
       "      <td>8.27%</td>\n",
       "      <td>R 1,465,486.20</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>R 13.03</td>\n",
       "      <td>R 378,765.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47067</td>\n",
       "      <td>7.73%</td>\n",
       "      <td>R 3,310,910.84</td>\n",
       "      <td>3.77%</td>\n",
       "      <td>R 12.24</td>\n",
       "      <td>R 576,140.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>61423</td>\n",
       "      <td>7.50%</td>\n",
       "      <td>R 5,696,871.95</td>\n",
       "      <td>6.49%</td>\n",
       "      <td>R 11.48</td>\n",
       "      <td>R 705,198.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>66861</td>\n",
       "      <td>8.14%</td>\n",
       "      <td>R 8,023,284.60</td>\n",
       "      <td>9.14%</td>\n",
       "      <td>R 12.75</td>\n",
       "      <td>R 852,480.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>63893</td>\n",
       "      <td>8.30%</td>\n",
       "      <td>R 9,225,249.60</td>\n",
       "      <td>10.51%</td>\n",
       "      <td>R 13.39</td>\n",
       "      <td>R 855,376.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55189</td>\n",
       "      <td>9.37%</td>\n",
       "      <td>R 9,437,714.52</td>\n",
       "      <td>10.75%</td>\n",
       "      <td>R 16.15</td>\n",
       "      <td>R 891,531.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>43152</td>\n",
       "      <td>11.54%</td>\n",
       "      <td>R 8,882,400.54</td>\n",
       "      <td>10.12%</td>\n",
       "      <td>R 19.36</td>\n",
       "      <td>R 835,498.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32407</td>\n",
       "      <td>14.91%</td>\n",
       "      <td>R 8,271,029.40</td>\n",
       "      <td>9.42%</td>\n",
       "      <td>R 30.25</td>\n",
       "      <td>R 980,317.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25417</td>\n",
       "      <td>20.12%</td>\n",
       "      <td>R 8,536,711.40</td>\n",
       "      <td>9.73%</td>\n",
       "      <td>R 46.59</td>\n",
       "      <td>R 1,184,071.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21192</td>\n",
       "      <td>29.01%</td>\n",
       "      <td>R 10,175,826.43</td>\n",
       "      <td>11.59%</td>\n",
       "      <td>R 82.96</td>\n",
       "      <td>R 1,757,985.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18413</td>\n",
       "      <td>41.11%</td>\n",
       "      <td>R 14,120,775.03</td>\n",
       "      <td>16.09%</td>\n",
       "      <td>R 149.10</td>\n",
       "      <td>R 2,745,438.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Count Purchase Rate prior_purchases in ZAR Value %  \\\n",
       "rfm_score_int                                                       \n",
       "3               5404         8.14%           R 109,079.32   0.12%   \n",
       "4              15422         8.02%           R 521,860.06   0.59%   \n",
       "5              29059         8.27%         R 1,465,486.20   1.67%   \n",
       "6              47067         7.73%         R 3,310,910.84   3.77%   \n",
       "7              61423         7.50%         R 5,696,871.95   6.49%   \n",
       "8              66861         8.14%         R 8,023,284.60   9.14%   \n",
       "9              63893         8.30%         R 9,225,249.60  10.51%   \n",
       "10             55189         9.37%         R 9,437,714.52  10.75%   \n",
       "11             43152        11.54%         R 8,882,400.54  10.12%   \n",
       "12             32407        14.91%         R 8,271,029.40   9.42%   \n",
       "13             25417        20.12%         R 8,536,711.40   9.73%   \n",
       "14             21192        29.01%        R 10,175,826.43  11.59%   \n",
       "15             18413        41.11%        R 14,120,775.03  16.09%   \n",
       "\n",
       "              AVG subs. spend in ZAR  \\\n",
       "rfm_score_int                          \n",
       "3                            R 12.52   \n",
       "4                            R 13.40   \n",
       "5                            R 13.03   \n",
       "6                            R 12.24   \n",
       "7                            R 11.48   \n",
       "8                            R 12.75   \n",
       "9                            R 13.39   \n",
       "10                           R 16.15   \n",
       "11                           R 19.36   \n",
       "12                           R 30.25   \n",
       "13                           R 46.59   \n",
       "14                           R 82.96   \n",
       "15                          R 149.10   \n",
       "\n",
       "              subsequent_purchases in ZAR (3 month window)  \n",
       "rfm_score_int                                               \n",
       "3                                              R 67,672.48  \n",
       "4                                             R 206,710.74  \n",
       "5                                             R 378,765.21  \n",
       "6                                             R 576,140.59  \n",
       "7                                             R 705,198.68  \n",
       "8                                             R 852,480.61  \n",
       "9                                             R 855,376.33  \n",
       "10                                            R 891,531.20  \n",
       "11                                            R 835,498.79  \n",
       "12                                            R 980,317.83  \n",
       "13                                          R 1,184,071.28  \n",
       "14                                          R 1,757,985.54  \n",
       "15                                          R 2,745,438.15  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_data = X_test.merge(target_data,how='left', left_on=['CustomerID','date'], right_on=['CustomerID','date'])\n",
    "summary = summary_data.groupby(['rfm_score_int']).agg({'recency':'count','monetary':'sum','target':'sum','subsequent_purchases':'sum'})\n",
    "summary = summary.rename(columns = {'recency':'Count','monetary':'prior_purchases','target':'Purchase Rate'})\n",
    "summary['prior_purchases in ZAR'] = summary.prior_purchases.apply(lambda x: f'R {x:,.2f}')\n",
    "summary['Value %'] = (summary['prior_purchases']/summary['prior_purchases'].sum()*100).apply(lambda x: f'{x:.2f}%')\n",
    "summary['AVG subs. spend in ZAR'] = (summary['subsequent_purchases']/summary.Count).apply(lambda x: f'R {x:.2f}')\n",
    "summary['subsequent_purchases in ZAR (3 month window)'] = summary.subsequent_purchases.apply(lambda x: f\"R {x:,.2f}\")\n",
    "summary['Purchase Rate'] =  (summary['Purchase Rate']/summary.Count).apply( lambda x: f'{x:.2%}')\n",
    "summary.drop(['prior_purchases','subsequent_purchases'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a9a4e9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Features",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Importances",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "af517217-7464-428f-95a0-4a03d2445440",
       "rows": [
        [
         "0",
         "recency",
         "58.25659942626953"
        ],
        [
         "1",
         "frequency",
         "5019.27978515625"
        ],
        [
         "2",
         "monetary",
         "636.1522827148438"
        ],
        [
         "3",
         "Gender",
         "42.82574462890625"
        ],
        [
         "4",
         "Age",
         "52.82544708251953"
        ],
        [
         "5",
         "Province",
         "41.938682556152344"
        ],
        [
         "6",
         "rfm_score_int",
         "1422.1400146484375"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recency</td>\n",
       "      <td>58.256599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frequency</td>\n",
       "      <td>5019.279785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monetary</td>\n",
       "      <td>636.152283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gender</td>\n",
       "      <td>42.825745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Age</td>\n",
       "      <td>52.825447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Province</td>\n",
       "      <td>41.938683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfm_score_int</td>\n",
       "      <td>1422.140015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Features  Importances\n",
       "0        recency    58.256599\n",
       "1      frequency  5019.279785\n",
       "2       monetary   636.152283\n",
       "3         Gender    42.825745\n",
       "4            Age    52.825447\n",
       "5       Province    41.938683\n",
       "6  rfm_score_int  1422.140015"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = zip(X_train.columns,model.get_score(importance_type='gain').values()),columns=['Features','Importances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e8e94c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(r'data\\PropensityToBuy.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d2f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
